---
title: 'DATA 624 PREDICTIVE ANALYTICS - Project 2'
author: "Melissa Bowman, Frederick Jones, Shoshana Farber, Gabriel Campos"
date: "Last edited `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook: default
  geometry: left=0.5cm,right=0.5cm,top=1cm,bottom=2cm
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
urlcolor: blue
---

# Libraries

```{r, warning=FALSE, message=FALSE}
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
```

# Assignment Description

**Project #2 (Team) Assignment**

This is role playing.  I am your new boss.  I am in charge of production at ABC Beverage and you are a team of data scientists reporting to me.  My leadership has told me that new regulations are requiring us to understand our manufacturing process, the predictive factors and be able to report to them our predictive model of pH.

Please use the historical data set I am providing.  Build and report the factors in BOTH a technical and non-technical report.  I like to use Word and Excel.  Please provide your non-technical report in a  business friendly readable document and your predictions in an Excel readable format.   The technical report should show clearly the models you tested and how you selected your final approach.
Please submit both Rpubs links and .rmd files or other readable formats for technical and non-technical reports.  Also submit the excel file showing the prediction of your models for pH.

# Data Import

We will first load in the data that is required for this analysis. 

```{r}
train_df <- readxl::read_xlsx('C:/Users/Shoshana/Documents/CUNY SPS/Data624_Collab/Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('C:/Users/Shoshana/Documents/CUNY SPS/Data624_Collab/Data/StudentEvaluation.xlsx')
```

`StudentData.xlsx` is our Training data set.

`StudentEvaluation.xlsx` is our Test data set.

# Exporatory Data Analysis

First, we can preview our dataset. 

```{r}
glimpse(train_df)
```

The dataset consists of 2,571 rows and 33 columns. Most of the variables are numeric, except for the first column indicating `Brand Code`. Our response variable is `PH`. 

We can take also take a look at the summary statistics for each of the numeric variables. 

```{r}
summary(train_df)
```

### NA Proportions

We can plot the missing values for each column to see what proportion of each variable is missing.

```{r}
plot_missing(train_df, 
             missing_only = T,
             ggtheme = theme_classic(),
             theme_config = list(legend.position = c("right")),
             geom_label_args = list("size" = 3, "label.padding" = unit(0.1, "lines")))
```

We can see that majority of the variables are missing less than 1% of values. For those that are missing more than 1% of the data, majority still fall below 5%. The variable with the most missing data, and possibly cause for concern, is `MFR`. However, even this is missing only about 8.25% of the data. 

```{r}
data.frame(missing = colSums(is.na(train_df))) |>
  filter(missing == 0) |>
  rownames()
```

`Pressure Vacuum` and `Air Pressurer` are the only variables not missing any data. 

```{r, warning=FALSE}
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE,
          cex.axis = .6)
```


### Distributions

We will now take a look at the distributions of the numeric variables. 

```{r}
DataExplorer::plot_histogram(train_df, nrow = 4L, ncol = 4L, ggtheme = theme_classic())
```

`Carb Pressure`, `Carb Temp`, `Fill Ounces`, `PC Volume`, and `PH` seem to be relatively normally distributed. 

`Hyd Pressure 1`, `PCS`, `PSC CO2`, `PSC Fill`, `Air Pressurer`, `Oxygen Filler`,`Pressure Vacuum`, and `Temperature` all seem to have a right skew. 

`Hyd Pressure2`, `Hyd Pressure3`, and `Mnf Flow` all seem to have a left skew, although there are also a fair amount of entries with a value at 0. `Filler Speed` and `MFR` also seem to have a left skew. 

Some variables, such as `Balling`, `Balling Lvl`, `Carb Rel`, and `Density` seem to be bimodally distributed. 

### Initial Findings

* Data consists of 2571 observations with 33 columns
* `Brand Code`:
  + Type character
  + Unordered categorical values
* Predictors:
  + Primarily doubles
  + 4 can be considered integers
  + High range variables:
    i. `Mnf Flow` -100.20 to 220.40
    ii. `Hyd Pressure1` -50.00 to 50.00
    iii. `Hyd Pressure2` -50.00 to 61.40
    iv. `Hyd Pressure3` -50.00 to 49.20
    v. `Hyd Pressure4` 68.00 to 140.00
* About 8% of the values for `MFR` is missing.  
* `Brand Code` is missing about 5% 
* Filler Speed is missing about 2%
* Remaining Variables have roughly 1% or less missing.  
* `Pressure.Vacuum`, `Air.Pressurer` have no NAs
* The Distribution of the variables can be grouped as **left skewed**, **right skewed** and for symmetric we can categorized as **relatively normal**
  + Relatively Normal Distributions:
    - `Carb.Pressure`
    - `Carb.Temp`
    -`Fill.Ounces`
    - `PC.Volume`
    - `PH` 
  + Left-skew Distributions:
    - `Carb.Flow`
    - `Filler.Speed`
    - `Mnf.Flow`
    - `MFR`
    - `Bowl.Setpoint`
    - `Filler.Level`
    - `Hyd.Pressure2`
    - `Hyd.Pressure3`
    -`Usage.cont`
    - `Carb.Pressure1`
    - `Filler.Speed`
  + Right-skew Distributions:
    - `Pressure.Setpoint`
    - `Fill.Pressure`
    - `Hyd.Pressure1`
    - `Temperature`
    - `Carb.Volume`
    - `PSC`
    - `PSC.CO2`
    - `PSC.Fill`
    - `Balling`
    - `Density`
    - `Hyd.Pressure4`
    - `Air.Pressurer`
    - `Alch.Rel`
    - `Carb.Rel`
    - `Oxygen.Filler`
    - `Balling.Lvl`
    - `Pressure.Vacuum`

```{r}
unique(train_df$`Brand Code`)
```

### Brand Code Distribution

`Brand Code` has 4 categorical values outside of NA (**A,B,C,D**). Let's examine the distribution of these codes.

```{r brand_code_dist, fig.height=5, warning=F}
train_df |>
  mutate(`Brand Code` = factor(`Brand Code`, levels = names(sort(table(`Brand Code`), decreasing = TRUE)))) |>
  ggplot(aes(x = `Brand Code`, fill = `Brand Code`)) +
  geom_bar(stat = "count") +
  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, color = "black") +
  labs(title = 'Brand Code Distribution', x = 'Brand Code', y = 'Frequency') +
  theme_minimal()
```

Majority of the entries in the dataset belong to `Brand Code` B. A and C have about the same number of entries. There are 120 missing values for `Brand Code`. 

### Correlation

First, we can plot a correlation matrix of our predictor variables to see which predictors are correlated with each other. 

```{r corrplot_eda, fig.height=15}
train_numeric_df <- train_df |>
  dplyr::select(where(is.numeric)) |>
  na.omit()

# Calculate correlation matrix
train_numeric_cor <- train_numeric_df |>
  dplyr::select(-PH) |>
  cor()

# Generate the correlation plot
corrplot(train_numeric_cor,
         method = "color",
         tl.col = "black",
         col = brewer.pal(n = 10,
                          name = "RdYlBu"),
         type = "lower",
         diag=FALSE,
         order = "hclust", 
         addCoef.col = "black",
         number.cex = 0.8,
         tl.cex = 0.8,
         cl.cex = 0.8,
         addCoefasPercent = TRUE,
         number.digits = 1)
```

We can see a few instances of multicollinearity in our predictor variables. `Carb Rel`, `Alch Rel`, `Density`, `Balling` and `Balling Level` are all significantly positively correlated with each other. `Hyd Pressue2` is significantly positively correlated with `Hyd Pressure 3`. Likewise, `Carb Temp` with `Carb Pressure`, `MFR` with `Fill Speed`, `Bowl Setpoint` with `Fill Level`, and `Pressure Setpoint` with `Fill Pressure`. 

There are also a number of variables that are highly negatively correlated with each other, such as `Pressure Vacuum` with `Hyd Pressure2` and `Hyd Pressure3`, `Mnf Flow` with `Filler Level` and `Bowl Setpoint`, and `Hyd Pressure4` with `Alch Rel`. 

A number of other variables also display moderate correlations with each other, as can be seen from the medium blue and medium red squares in the correlation plot. 

We will need to address these multicollinearity issues in our models. 

### PH

With `PH` being our response variable, assessing `PH`'s correlation with other variables is needed.

```{r ph_corrplot, fig.height=7}
train_numeric_df |>
  dplyr::select(-PH) |>  # Exclude 'PH' from predictors if needed
  cor(train_numeric_df$PH) |>  # Calculate correlations with 'PH'
  as.data.frame() |>
  rownames_to_column(var = "Predictor") |>
  filter(Predictor != "PH") |>  # Ensure 'PH' is not included as its own predictor
  mutate(Predictor = fct_reorder(factor(Predictor), V1)) |>  # Reorder factors by correlation for plotting
  ggplot(aes(x = Predictor, y = V1, label = round(V1, 2))) +
    geom_col(aes(fill = ifelse(V1 < 0, "negative", "positive"))) +
    geom_text(color = "black", size = 3, vjust = -0.3) +
    coord_flip() +
    labs(title = "Correlations: pH", x = "Predictors", y = "Correlation Coefficient") +
    theme_minimal() +
    theme(legend.position = "none")
```

Individually, there are no variables that are extremely correlated with `PH`. `Mnf Flow` has the largest correlation of about -0.46. The most significantly positively correlated variables with `PH` are `Bowl Setpoint` and `Filler Level`. The most significantly negatively correlated variables, other than `Mnf Flow`, are `Usage cont`, `Fill Pressure`, and `Pressure Setpoint`. 

## Data Cleanup

* Transform `Brand Code` which will be mutated to categorized factors as in **r chunk** `brand_code_dist`. 
* Identify unhelpful data:
  + Identifying variables with zero variance (`zeroVar`) variables
  + Identify near-zero variance (nzv).
  + Remove an rows with NAs in our response variable, as it will interfere with analysis in the future.

```{r}
train_df%>%
  dplyr::filter(!is.na(PH))
```

```{r}
train_df<-train_df%>%
  dplyr::filter(!is.na(PH))
```


```{r}
train_df<- train_df %>% 
  dplyr::mutate(`Brand Code` = factor(`Brand Code`, 
                         levels = c('A','B','C','D','not known'), 
                         ordered = FALSE))
```


```{r}
nzv_df <- nearZeroVar(train_df, saveMetrics= TRUE)
nzv_df <- as.data.frame(nzv_df) %>% 
  rownames_to_column(var = "Predictor") 

nzv_filtered_df <- nzv_df %>% 
  filter(nzv == TRUE)

ggplot(nzv_filtered_df, aes(x = Predictor, y = percentUnique, fill = freqRatio > 0.95)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Near-Zero Variance Predictors", 
       x = "Predictors", 
       y = "Percentage of Unique Values") +
  theme_minimal()

print(nzv_filtered_df)
```

# Modeling

## Preliminary Data Processing

Pre-processing Steps:

* Transform the data using as.dataframe() otherwise `preProcess` function from `caret` fails
* Remove separate response variable from predictors
* leverage `caret` package method [preProcess](https://www.rdocumentation.org/packages/caret/versions/6.0-92/topics/preProcess) to transform data using methods:
  + knnImpute - nearest neighbor to impute missing data
  + nzv = remove near-zero values identified above
  + corr = filters out highly correlated values addressing
  multicollinearity
  + center = subtracts the mean of the predictor's data (again from
  the data in x) from the predictor values 
  + scale = divides by the standard deviation.
  + BoxCox = normalizes data
* Use the `predict` function to process the list variables created with `preProcess()` to recreate the dataframe.
* Rejoin `PH` to the dataframe.
  
  


```{r}
set.seed(1234)

train_df<- as.data.frame(train_df)

#remove pH from the train data set in order to only transform the predictors
train_preprocess_df <- train_df %>% 
  dplyr::select(-c(PH))

preProc_ls <- preProcess(train_preprocess_df, method = c("knnImpute", "nzv", "corr", "center", "scale", "BoxCox"))

train_preProc_df <- predict(preProc_ls, train_preprocess_df)
train_preProc_df$PH <- train_df$PH 
# To verify no NAs produced when recombining
train_preProc_df%>%
  dplyr::filter(is.na(PH))
```

## Data Partition

```{r}
training_set_df <- createDataPartition(train_preProc_df$PH, p=0.8, list=FALSE)

train_proc_df <- train_preProc_df[training_set_df,]
eval_proc_df <- train_preProc_df[-training_set_df,]
```

