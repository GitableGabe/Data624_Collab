random_forest_model <- data.frame(Model = "Random Forest",
#mean absolute error
MAE = ModelMetrics::mae(predictions3$Total.Revenue, predictions3$...1),
#rmse Root Mean Squared Error
RMSE = ModelMetrics::rmse(predictions3$Total.Revenue, predictions3$...1),
#r squared
R2 = R2(predictions3$Total.Revenue, predictions3$...1)
)
random_forest_model
set.seed(333)
train_tuned_rf <- train_1k1 %>%
select(-Total.Revenue)
bestmtry <- tuneRF(train_tuned_rf,train_1k1$Total.Revenue, stepFactor = 2, improve = 0.01,
trace=T, plot= T, doBest=TRUE, importance=TRUE)
bestmtry
#importance(bestmtry)
# Get variable importance from the model fit
ImpData <- as.data.frame(importance(bestmtry))
ImpData$Var.Names <- row.names(ImpData)
ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="lightgreen") +
geom_point(aes(size = IncNodePurity), color="darkgreen", alpha=1) +
theme_light() +
coord_flip() +
theme(
legend.position="bottom",
panel.grid.major.y = element_blank(),
panel.border = element_blank(),
axis.ticks.y = element_blank()
)
predictions4 <- predict(bestmtry, newdata = test_1k1) %>%
bind_cols(test_1k1)
predictions4$...1 <- as.numeric(predictions4$...1)
random_forest_tuned_model <- data.frame(Model = "Tuned Random Forest",
#mean absolute error
MAE = ModelMetrics::mae(predictions4$Total.Revenue, predictions4$...1),
#rmse Root Mean Squared Error
RMSE = ModelMetrics::rmse(predictions4$Total.Revenue, predictions4$...1),
#r squared
R2 = caret::R2(predictions4$Total.Revenue, predictions4$...1)
)
random_forest_tuned_model
set.seed(321)
sample_1k_train <- df_1k_num$Total.Revenue %>%
createDataPartition(p = 0.8, list = FALSE)
df_train_1k  <- df_1k_num[sample_1k_train, ]
df_test_1k <- df_1k_num[-sample_1k_train, ]
model<- lm(Total.Revenue~., data=df_train_1k )
vif_values<-car::vif(model)
print(vif_values)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(tidyr)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(tidyr)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
model1 <- randomForest(y ~ ., data = simulated,
importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
rownames(rfImp1) <- paste0("V", 1:10)
rfImp1_sorted <- rfImp1[order(-rfImp1$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp1_sorted)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2<-simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
rownames(rfImp2) <- c(paste0("V", 1:10), "duplicate1")
rfImp2_sorted <- rfImp2[order(-rfImp2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp2_sorted)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
set.seed(624)
model_gbm<- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(model_gbm)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
cube_model_v2<-varImp(cubist_model)
rownames(cube_model_v2) <- c(paste0("V", 1:10), "duplicate1")
cubist_sorted <- cube_model_v2[order(-cube_model_v2$Overall), , drop = FALSE]
print(cubist_sorted)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
df_sim <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = df_sim, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
set.seed(624)
gbm_model <- gbm.fit(train_predictors, train_chem$Yield, distribution = "gaussian")
set.seed(624)
gbm_model <- gbm.fit(train_pred, train_chem$Yield, distribution = "gaussian")
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(tidyr)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
model1 <- randomForest(y ~ ., data = simulated,
importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
rownames(rfImp1) <- paste0("V", 1:10)
rfImp1_sorted <- rfImp1[order(-rfImp1$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp1_sorted)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2<-simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
rownames(rfImp2) <- c(paste0("V", 1:10), "duplicate1")
rfImp2_sorted <- rfImp2[order(-rfImp2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp2_sorted)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
set.seed(624)
model_gbm<- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(model_gbm)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
cube_model_v2<-varImp(cubist_model)
rownames(cube_model_v2) <- c(paste0("V", 1:10), "duplicate1")
cubist_sorted <- cube_model_v2[order(-cube_model_v2$Overall), , drop = FALSE]
print(cubist_sorted)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
df_sim <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = df_sim, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
set.seed(624)
gbm_model <- gbm.fit(train_pred, train_chem$Yield, distribution = "gaussian")
set.seed(624)
gbm_model <- gbm.fit(train_pred, chem_train$Yield, distribution = "gaussian")
gbm_model
gbm_pred <- predict(gbm_model, newdata = test_pred)
postResample(pred = gbm_pred, obs = chem_train$Yield)
set.seed(624)
cube_model <- cubist(train_pred, chem_train$Yield)
cube_model
cube_pred <- predict(cube_model, newdata = test_pred)
postResample(pred = cube_pred, obs = chem_train$Yield)
set.seed(624)
gbm_model <- gbm.fit(train_pred, chem_train$Yield, distribution = "gaussian")
gbm_model
gbm_pred <- predict(gbm_model, newdata = test_pred)
postResample(pred = gbm_pred, obs = chem_test$Yield)
set.seed(624)
#fit the model
rf_model <- randomForest(train_pred, chem_train$Yield, importance = TRUE, ntrees = 1000)
rf_model
rf_pred <- predict(rf_model, newdata = test_pred)
postResample(pred = rf_pred, obs = chem_test$Yield)
head(varImp(rf_model),10)
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(tidyr)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
model1 <- randomForest(y ~ ., data = simulated,
importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
rownames(rfImp1) <- paste0("V", 1:10)
rfImp1_sorted <- rfImp1[order(-rfImp1$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp1_sorted)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2<-simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
rownames(rfImp2) <- c(paste0("V", 1:10), "duplicate1")
rfImp2_sorted <- rfImp2[order(-rfImp2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp2_sorted)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
set.seed(624)
model_gbm<- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(model_gbm)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
cube_model_v2<-varImp(cubist_model)
rownames(cube_model_v2) <- c(paste0("V", 1:10), "duplicate1")
cubist_sorted <- cube_model_v2[order(-cube_model_v2$Overall), , drop = FALSE]
print(cubist_sorted)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
df_sim <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = df_sim, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(tidyr)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
model1 <- randomForest(y ~ ., data = simulated,
importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
rownames(rfImp1) <- paste0("V", 1:10)
rfImp1_sorted <- rfImp1[order(-rfImp1$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp1_sorted)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2<-simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
rownames(rfImp2) <- c(paste0("V", 1:10), "duplicate1")
rfImp2_sorted <- rfImp2[order(-rfImp2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp2_sorted)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
set.seed(624)
model_gbm<- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(model_gbm)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
cube_model_v2<-varImp(cubist_model)
rownames(cube_model_v2) <- c(paste0("V", 1:10), "duplicate1")
cubist_sorted <- cube_model_v2[order(-cube_model_v2$Overall), , drop = FALSE]
print(cubist_sorted)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
df_sim <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = df_sim, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
set.seed(624)
gbm_model <- gbm.fit(train_pred, chem_train$Yield, distribution = "gaussian")
gbm_model
gbm_pred <- predict(gbm_model, newdata = test_pred)
postResample(pred = gbm_pred, obs = chem_test$Yield)
set.seed(624)
cube_model <- cubist(train_pred, chem_train$Yield)
cube_model
cube_pred <- predict(cube_model, newdata = test_pred)
postResample(pred = cube_pred, obs = chem_test$Yield)
set.seed(624)
#fit the model
rf_model <- randomForest(train_pred, chem_train$Yield, importance = TRUE, ntrees = 1000)
rf_model
rf_pred <- predict(rf_model, newdata = test_pred)
postResample(pred = rf_pred, obs = chem_test$Yield)
rf_model_v2<-varImp(rf_model)
rownames(rf_model_v2) <- c(paste0("V", 1:10), "duplicate1")
View(rf_model_v2)
#rownames(rf_model_v2) <- c(paste0("V", 1:10), "duplicate1")
rf_model_sorted <- rf_model_v2[order(-rf_model_v2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
head(rf_model_sorted,10)
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
rpart_tree <- rpart(Yield ~., data = chem_train)
rpart.plot(rpart_tree)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
StudentData_df <- read_xlsx('./Data/StudentData.xlsx')
StudentData_df <- read_xlsx('./Data/StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('./Data/StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('.Data/StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('.\Data\StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('.\\Data\\StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(readxl)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
setwd("C:/Users/xusef/Documents/GitableGabe/Data624_Collab")
StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
#StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('..Data/StudentData.xlsx')
#StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
StudentData_df <- readxl::read_xlsx('../Data/StudentData.xlsx')
#StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
#StudentEval_df <- readxl::read_xlsx('/Data/StudentEvaluation.xlsx')
StudentData_df <- readxl::read_xlsx('../Data/StudentData.xlsx')
StudentEval_df <- readxl::read_xlsx('../Data/StudentEvaluation.xlsx')
StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
StudentEval_df <- readxl::read_xlsx('/Data/StudentEvaluation.xlsx')
