train_preProc_df$PH <- train_df$PH
# To verify no NAs produced when recombining
train_preProc_df%>%
dplyr::filter(is.na(PH))
training_set_df <- createDataPartition(train_preProc_df$PH, p=0.8, list=FALSE)
train_proc_pls_df <- train_preProc_df[training_set_df,]
eval_proc_pls_df <- train_preProc_df[-training_set_df,]
set.seed(222)
y_train <- subset(train_proc_pls_df, select = -c(PH))
y_test <- subset(eval_proc_pls_df, select = -c(PH))
set.seed(2341)
#generate model
pls_model <- train(y_train, train_proc_pls_df$PH,
method='pls',
metric='Rsquared',
tuneLength=10,
trControl=trainControl(method = "cv",  number = 10))
#evaluate model metrics
plsPred <-predict(pls_model, newdata=y_test)
plsReSample <- postResample(pred=plsPred, obs = eval_proc_pls_df$PH)
plsReSample %>% kable() %>% kable_paper()
head(train_proc_df)
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(pls)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
train_df <- readxl::read_xlsx('Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('Data/StudentEvaluation.xlsx')
glimpse(train_df)
str(train_df)
summary(train_df)
glimpse(test_df)
str(test_df)
summary(test_df)
missing_train_df <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_train_df, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
labs(y = "NA Proportion", x = "Variables") +
coord_flip()
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE,
cex.axis = .6)
DataExplorer::plot_histogram(train_df, nrow = 3L, ncol = 4L)
unique(train_df$`Brand Code`)
train_df %>%
mutate(`Brand Code` = factor(`Brand Code`, levels = names(sort(table(`Brand Code`), decreasing = TRUE)))) %>%
ggplot(aes(x = `Brand Code`, fill = `Brand Code`)) +
geom_bar(stat = "count") +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, color = "black") +
labs(title = 'Brand Code Distribution', x = 'Brand Code', y = 'Frequency') +
theme_minimal()
train_numeric_df <- train_df %>%
dplyr::select(where(is.numeric)) %>%
na.omit()
# Calculate correlation matrix
train_numeric_cor <- cor(train_numeric_df)
# Generate the correlation plot
corrplot(train_numeric_cor,
method = "color",
tl.col = "black",
col = brewer.pal(n = 10,
name = "RdYlBu"),
type = "lower",
order = "hclust",
addCoef.col = "black",
number.cex = 0.8,
tl.cex = 0.8,
cl.cex = 0.8,
addCoefasPercent = TRUE,
number.digits = 1)
train_numeric_df %>%
dplyr::select(-PH) %>%  # Exclude 'PH' from predictors if needed
cor(train_numeric_df$PH) %>%  # Calculate correlations with 'PH'
as.data.frame() %>%
rownames_to_column(var = "Predictor") %>%
filter(Predictor != "PH") %>%  # Ensure 'PH' is not included as its own predictor
mutate(Predictor = fct_reorder(factor(Predictor), V1)) %>%  # Reorder factors by correlation for plotting
ggplot(aes(x = Predictor, y = V1, label = round(V1, 2))) +
geom_col(fill = "lightgreen") +
geom_text(color = "black", size = 3, vjust = -0.3) +
coord_flip() +
labs(title = "Correlations: pH", x = "Predictors", y = "Correlation Coefficient") +
theme_minimal()
train_df%>%
dplyr::filter(!is.na(PH))
train_df<-train_df%>%
dplyr::filter(!is.na(PH))
train_df<- train_df %>%
dplyr::mutate(`Brand Code` = factor(`Brand Code`,
levels = c('A','B','C','D','not known'),
ordered = FALSE))
nzv_df <- nearZeroVar(train_df, saveMetrics= TRUE)
nzv_df <- as.data.frame(nzv_df) %>%
rownames_to_column(var = "Predictor")
nzv_filtered_df <- nzv_df %>%
filter(nzv == TRUE)
ggplot(nzv_filtered_df, aes(x = Predictor, y = percentUnique, fill = freqRatio > 0.95)) +
geom_col(position = "dodge") +
coord_flip() +
labs(title = "Near-Zero Variance Predictors",
x = "Predictors",
y = "Percentage of Unique Values") +
theme_minimal()
print(nzv_filtered_df)
set.seed(1234)
train_df<- as.data.frame(train_df)
#remove pH from the train data set in order to only transform the predictors
train_preprocess_df <- train_df %>%
dplyr::select(-c(PH))
preProc_ls <- preProcess(train_preprocess_df, method = c("knnImpute", "nzv", "corr", "center", "scale", "BoxCox"))
train_preProc_df <- predict(preProc_ls, train_preprocess_df)
train_preProc_df$PH <- train_df$PH
# To verify no NAs produced when recombining
train_preProc_df%>%
dplyr::filter(is.na(PH))
training_set_df <- createDataPartition(train_preProc_df$PH, p=0.8, list=FALSE)
train_proc_df <- train_preProc_df[training_set_df,]
eval_proc_df <- train_preProc_df[-training_set_df,]
train_proc_pls_df<-train_proc_df
eval_proc_pls_df<-eval_proc_df
set.seed(222)
y_train <- subset(train_proc_pls_df, select = -c(PH))
y_test <- subset(eval_proc_pls_df, select = -c(PH))
set.seed(2341)
#generate model
pls_model <- train(y_train, train_proc_pls_df$PH,
method='pls',
metric='Rsquared',
tuneLength=10,
trControl=trainControl(method = "cv",  number = 10))
#evaluate model metrics
plsPred <-predict(pls_model, newdata=y_test)
plsReSample <- postResample(pred=plsPred, obs = eval_proc_pls_df$PH)
plsReSample %>% kable() %>% kable_paper()
head(train_proc_df)
head(eval_proc_df)
eval_proc_df <- na.omit(eval_proc_df)
train_proc_df <- na.omit(train_proc_df)
# Install and load the necessary packages
library(pls)
# Assuming train_proc_df contains your training data
# Fit PLSR model
plsr_model <- plsr(PH ~ ., data = train_proc_df, ncomp = 10)  # Set a reasonable maximum number of components
# Extract the proportion of variance explained by each component
variance_explained <- summary(plsr_model)$val$prop
# Create a scree plot
plot(1:length(variance_explained), variance_explained, type = "b",
xlab = "Number of Components", ylab = "Proportion of Variance Explained",
main = "Scree Plot for PLSR")
# Add a horizontal line at 0.05 for reference (adjust as needed)
abline(h = 0.05, col = "red", lty = 2)
# Add text indicating the percentage of variance explained by each component
text(1:length(variance_explained), variance_explained,
labels = paste0(round(variance_explained * 100, 2), "%"),
pos = 3, cex = 0.8)
# Add a legend
legend("topright", legend = "Threshold (e.g., 0.05)", lty = 2, col = "red", bty = "n")
# Create a scree plot for the first few components
plot(1:length(variance_explained), variance_explained, type = "b",
xlab = "Number of Components", ylab = "Proportion of Variance Explained",
main = "Scree Plot for PLSR")
# Zoom in on the first few components (adjust xlim as needed)
xlim <- c(1, min(10, length(variance_explained)))  # Adjust the maximum number of components if needed
plot(1:length(variance_explained), variance_explained, type = "b",
xlab = "Number of Components", ylab = "Proportion of Variance Explained",
main = "Scree Plot for PLSR", xlim = xlim)
# Add a horizontal line at 0.05 for reference (adjust as needed)
abline(h = 0.05, col = "red", lty = 2)
# Add text indicating the percentage of variance explained by each component
text(1:length(variance_explained), variance_explained,
labels = paste0(round(variance_explained * 100, 2), "%"),
pos = 3, cex = 0.8)
# Add a legend
legend("topright", legend = "Threshold (e.g., 0.05)", lty = 2, col = "red", bty = "n")
# Fit PLSR model
plsr_model <- plsr(PH ~ ., data = train_proc_df, ncomp = 5)  # Specify the number of components (e.g., 5)
summary(plsr_model)
# Predict PH values for evaluation/test set
predictions <- predict(plsr_model, newdata = eval_proc_df)
plot(plsr_model)
sum(is.na(predictions))
# Calculate Mean Squared Error (MSE)
on <- predictions - eval_proc_df$PH
on <- on^2
mse <- mean(on)
mse# Calculate R-squared (R²)
actual <- eval_proc_df$PH
ss_total <- sum((actual - mean(actual))^2)
ss_residual <- sum((actual - predictions)^2)
r_squared <- 1 - (ss_residual / ss_total)
# Print MSE and R²
cat("Mean Squared Error (MSE):", mse, "\n")
cat("R-squared (R²):", r_squared, "\n")
# Fit regression tree model to training data
tree_model <- rpart(PH ~ ., data = train_proc_df)
# Make predictions on evaluation/test data
tree_predictions <- predict(tree_model, newdata = eval_proc_df)
# Calculate Mean Squared Error (MSE)
tree_mse <- mean((tree_predictions - eval_proc_df$PH)^2)
# Calculate R-squared (R²)
tree_actual <- eval_proc_df$PH
tree_ss_total <- sum((tree_actual - mean(tree_actual))^2)
tree_ss_residual <- sum((tree_actual - tree_predictions)^2)
tree_r_squared <- 1 - (tree_ss_residual / tree_ss_total)
# Print MSE and R²
cat("Regression Tree Model:\n")
cat("Mean Squared Error (MSE):", tree_mse, "\n")
cat("R-squared (R²):", tree_r_squared, "\n")
summary(tree_model)
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
library(earth)
library(randomForest)
train_df <- readxl::read_xlsx('Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('Data/StudentData.xlsx')
glimpse(train_df)
summary(train_df)
plot_missing(train_df,
missing_only = T,
ggtheme = theme_classic(),
theme_config = list(legend.position = c("right")),
geom_label_args = list("size" = 3, "label.padding" = unit(0.1, "lines")))
data.frame(missing = colSums(is.na(train_df))) |>
filter(missing == 0) |>
rownames()
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE,
cex.axis = .6)
DataExplorer::plot_histogram(train_df, nrow = 4L, ncol = 4L, ggtheme = theme_classic())
unique(train_df$`Brand Code`)
train_df |>
mutate(`Brand Code` = factor(`Brand Code`, levels = names(sort(table(`Brand Code`), decreasing = TRUE)))) |>
ggplot(aes(x = `Brand Code`, fill = `Brand Code`)) +
geom_bar(stat = "count") +
geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5, color = "black") +
labs(title = 'Brand Code Distribution', x = 'Brand Code', y = 'Frequency') +
theme_minimal()
train_numeric_df <- train_df |>
dplyr::select(where(is.numeric)) |>
na.omit()
# Calculate correlation matrix
train_numeric_cor <- train_numeric_df |>
dplyr::select(-PH) |>
cor()
# Generate the correlation plot
corrplot(train_numeric_cor,
method = "color",
tl.col = "black",
col = brewer.pal(n = 10,
name = "RdYlBu"),
type = "lower",
diag=FALSE,
order = "hclust",
addCoef.col = "black",
number.cex = 0.8,
tl.cex = 0.8,
cl.cex = 0.8,
addCoefasPercent = TRUE,
number.digits = 1)
train_numeric_df |>
dplyr::select(-PH) |>  # Exclude 'PH' from predictors if needed
cor(train_numeric_df$PH) |>  # Calculate correlations with 'PH'
as.data.frame() |>
rownames_to_column(var = "Predictor") |>
filter(Predictor != "PH") |>  # Ensure 'PH' is not included as its own predictor
mutate(Predictor = fct_reorder(factor(Predictor), V1)) |>  # Reorder factors by correlation for plotting
ggplot(aes(x = Predictor, y = V1, label = round(V1, 2))) +
geom_col(aes(fill = ifelse(V1 < 0, "negative", "positive"))) +
geom_text(color = "black", size = 3, vjust = -0.3) +
coord_flip() +
labs(title = "Correlations: pH", x = "Predictors", y = "Correlation Coefficient") +
theme_minimal() +
theme(legend.position = "none")
names(train_df) <- snakecase::to_snake_case(names(train_df))
names(test_df) <- snakecase::to_snake_case(names(test_df))
train_df <- train_df |>
filter(!is.na(ph))
train_df <- train_df |>
dplyr::mutate(brand_code = ifelse(is.na(brand_code), "Unknown", brand_code),
brand_code = factor(brand_code, levels = c('A','B','C','D','Unknown'), ordered = FALSE))
test_df <- test_df |>
dplyr::mutate(brand_code = ifelse(is.na(brand_code), "Unknown", brand_code),
brand_code = factor(brand_code, levels = c('A','B','C','D','Unknown'), ordered = FALSE))
nzv_df <- nearZeroVar(train_df, saveMetrics= TRUE)
nzv_df <- as.data.frame(nzv_df) %>%
rownames_to_column(var = "Predictor")
nzv_filtered_df <- nzv_df %>%
filter(nzv == TRUE)
ggplot(nzv_filtered_df, aes(x = Predictor, y = percentUnique, fill = freqRatio > 0.95)) +
geom_col(position = "dodge") +
coord_flip() +
labs(title = "Near-Zero Variance Predictors",
x = "Predictors",
y = "Percentage of Unique Values") +
theme_minimal()
print(nzv_filtered_df)
train_df <- as.data.frame(train_df)
test_df <- as.data.frame(test_df)
#remove pH from the train data set in order to only transform the predictors
train_preprocess_df <- train_df |>
dplyr::select(-c(ph))
preProc_ls <- preProcess(train_preprocess_df, method = c("knnImpute", "nzv", "corr", "center", "scale", "BoxCox"))
train_preProc_df <- predict(preProc_ls, train_preprocess_df)
# rejoin with pH
train_preProc_df$ph <- train_df$ph
#remove pH from the test data set in order to only transform the predictors
test_preprocess_df <- test_df |>
dplyr::select(-c(ph))
preProc_ls <- preProcess(test_preprocess_df, method = c("knnImpute", "nzv", "corr", "center", "scale", "BoxCox"))
test_preProc_df <- predict(preProc_ls, test_preprocess_df)
# rejoin with pH
test_preProc_df$ph <- test_df$ph
# verify no NAs remain
colSums(is.na(train_preProc_df))
set.seed(1234)  # for reproducibility
training_set_df <- createDataPartition(train_preProc_df$ph, p=0.8, list=FALSE)
train <- train_preProc_df[training_set_df,]
eval <- train_preProc_df[-training_set_df,]
lm <- lm(ph ~ ., data=train)
summary(lm)
lm_update <- step(lm, direction="both", trace=0)
summary(lm_update)
par(mfrow = c(1,2))
plot(lm_update, which = c(1,2))
lm_pred <- predict(lm_update, eval)
(lm_metrics <- postResample(lm_pred, eval$ph))
set.seed(2341)
# generate model
pls_model <- train(ph ~ .,
data=train,
method='pls',
metric='Rsquared',
tuneLength=10,
trControl=trainControl(method = "cv",  number = 10))
plot(pls_model)
pls_model
plot(varImp(pls_model))
# evaluate model metrics
pls_pred <- predict(pls_model, eval)
(pls_metrics <- postResample(pls_pred, eval$ph))
set.seed(613)
knn_model <- train(ph ~ .,
data = train,
method = "knn",
tuneLength = 10)
knn_model
plot(varImp(knn_model))
knn_pred <- predict(knn_model, eval)
(knn_metrics <- postResample(knn_pred, eval$ph))
marsGrid <- expand.grid(.degree = 1:2, .nprune = 2:38)
set.seed(613)
mars_model <- train(ph ~ .,
data = train,
method = "earth",
tuneGrid = marsGrid,
trControl = trainControl(method = "cv"))
View(test_preprocess_df)
View(test_preProc_df)
mars_model
plot(varImp(mars_model))
mars_pred <- predict(mars_model, eval)
(mars_metrics <- postResample(mars_pred, eval$ph))
set.seed(613)
svm_model <- train(ph ~ .,
data = train,
method = "svmRadial",
tuneLength = 14,
trControl = trainControl(method = "cv"))
View(train)
svm_model
plot(varImp(svm_model))
svm_pred <- predict(svm_model, eval)
(svm_metrics <- postResample(svm_pred, eval$ph))
set.seed(613)
rf_model <- randomForest(ph ~ .,
data = train,
importance = TRUE,
ntree = 1000)
rf_model
rf_model
varImp(rf_model) |>
arrange(desc(Overall)) |>
knitr::kable()
rf_pred <- predict(rf_model, eval)
(rf_metrics <- postResample(rf_pred, eval$ph))
rbind(lm_metrics, pls_metrics, knn_metrics, mars_metrics, svm_metrics, rf_metrics) |>
knitr::kable()
View(test_preprocess_df)
View(test_df)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(test_preProc_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
# Reorder the columns to have "ph" and "predicted_ph" next to each other
merged_df <- merged_df[, c(names(merged_df)[!names(merged_df) %in% c("predicted_ph")], "predicted_ph")]
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
# Reorder the columns to have "ph" and "predicted_ph" next to each other
merged_df <- merged_df[, c(names(merged_df)[!names(merged_df) %in% c("predicted_ph")], "predicted_ph")]
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
# Reorder the columns to have "ph" and "predicted_ph" next to each other
merged_df <- merged_df[, c(setdiff(names(merged_df), c("ph", "predicted_ph")), "ph", "predicted_ph")]
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
# Calculate the percentage difference
merged_df$percentage_difference <- ((merged_df$ph - merged_df$predicted_ph) / merged_df$ph) * 100
# Reorder the columns to have "ph", "predicted_ph", and "percentage_difference" as the last three columns
merged_df <- merged_df[, c(setdiff(names(merged_df), c("ph", "predicted_ph", "percentage_difference")),
"ph", "predicted_ph", "percentage_difference")]
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
predictions <- predict(rf_model, newdata = test_preProc_df)
test_preProc_df$predicted_ph <- predictions
# Join the original test_df with the predictions
merged_df <- cbind(test_df, predicted_ph = predictions)
# Calculate the percentage difference
merged_df$percentage_difference <- ((merged_df$ph - merged_df$predicted_ph) / merged_df$ph) * 100
# Reorder the columns to have "ph", "predicted_ph", and "percentage_difference" as the last three columns
merged_df <- merged_df[, c(setdiff(names(merged_df), c("ph", "predicted_ph", "percentage_difference")),
"ph", "predicted_ph", "percentage_difference")]
library(openxlsx)
output_file <- "predictions.xlsx"
write.xlsx(merged_df, file = output_file, rowNames = FALSE)
