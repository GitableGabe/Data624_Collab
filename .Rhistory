simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
model1 <- randomForest(y ~ ., data = simulated,
importance = TRUE,
ntree = 1000)
rfImp1 <- varImp(model1, scale = FALSE)
rownames(rfImp1) <- paste0("V", 1:10)
rfImp1_sorted <- rfImp1[order(-rfImp1$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp1_sorted)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2<-simulated
simulated2$duplicate1 <- simulated2$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE,
ntree = 1000)
rfImp2 <- varImp(model2, scale = FALSE)
rownames(rfImp2) <- c(paste0("V", 1:10), "duplicate1")
rfImp2_sorted <- rfImp2[order(-rfImp2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
print(rfImp2_sorted)
model3 <- cforest(y ~., data = simulated)
order(-varimp(model3, conditional = FALSE)) #default conditional: FALSE
order(-varimp(model3, conditional = TRUE))
set.seed(624)
model_gbm<- gbm(y ~., data = simulated, distribution = "gaussian")
summary.gbm(model_gbm)
simulated_x <- subset(simulated, select = -c(y))
cubist_model <- cubist(x = simulated_x, y = simulated$y, committees = 100)
cube_model_v2<-varImp(cubist_model)
rownames(cube_model_v2) <- c(paste0("V", 1:10), "duplicate1")
cubist_sorted <- cube_model_v2[order(-cube_model_v2$Overall), , drop = FALSE]
print(cubist_sorted)
set.seed(624)
#samples for predictors
low <- sample(0:50, 500, replace = T)
medium <- sample(0:500, 500, replace = T)
high <- sample(0:5000, 500, replace = T)
#response
y <- low + medium + high + rnorm(250)
#check variance of predictors
var(low)
var(medium)
var(high)
df_sim <- data.frame(low, medium, high, y)
diff_gran_model <- randomForest(y ~., data = df_sim, importance = TRUE, ntree = 1000)
varImp(diff_gran_model, scale=FALSE)
#load data
data(ChemicalManufacturingProcess)
set.seed(624)
imputed_data <- preProcess(ChemicalManufacturingProcess, method = c("knnImpute","nzv", "corr"))
df_full <- predict(imputed_data, ChemicalManufacturingProcess)
chem_index <- createDataPartition(df_full$Yield , p=.8, list=F)
chem_train <-  df_full[chem_index,]
chem_test <- df_full[-chem_index,]
train_pred <- chem_train[-c(1)]
test_pred<-  chem_test[-c(1)]
set.seed(624)
gbm_model <- gbm.fit(train_pred, chem_train$Yield, distribution = "gaussian")
gbm_model
gbm_pred <- predict(gbm_model, newdata = test_pred)
postResample(pred = gbm_pred, obs = chem_test$Yield)
set.seed(624)
cube_model <- cubist(train_pred, chem_train$Yield)
cube_model
cube_pred <- predict(cube_model, newdata = test_pred)
postResample(pred = cube_pred, obs = chem_test$Yield)
set.seed(624)
#fit the model
rf_model <- randomForest(train_pred, chem_train$Yield, importance = TRUE, ntrees = 1000)
rf_model
rf_pred <- predict(rf_model, newdata = test_pred)
postResample(pred = rf_pred, obs = chem_test$Yield)
rf_model_v2<-varImp(rf_model)
rownames(rf_model_v2) <- c(paste0("V", 1:10), "duplicate1")
View(rf_model_v2)
#rownames(rf_model_v2) <- c(paste0("V", 1:10), "duplicate1")
rf_model_sorted <- rf_model_v2[order(-rf_model_v2$Overall), , drop = FALSE] # 'drop = FALSE' ensures the result is still a data frame
head(rf_model_sorted,10)
library(AppliedPredictiveModeling)
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
rpart_tree <- rpart(Yield ~., data = chem_train)
rpart.plot(rpart_tree)
setwd("C:/Users/xusef/Documents/GitableGabe/Data624")
library(readr)
library(tidyverse)
library(tidymodels)
library(psych)
library(caret)
library(rpart)
library(rpart.plot)
library(corrplot)
library(RColorBrewer)
library(labelled)
library(ggplot2)
library(ggforce)
library(kableExtra)
library(gridExtra)
library(Metrics)
url<-"https://raw.githubusercontent.com/GitableGabe/Data624_Data/main/"
df_1k <- read.csv(paste0(url,"1000%20Sales%20Records.csv"))
df_100k <- read.csv(paste0(url,"100000%20Sales%20Records.csv"))
str(df_1k)
str(df_100k)
kable(as.data.frame(table(df_1k$Region)) %>% arrange(desc(Freq)),
caption = "Frequency Region df_1k")
kable(as.data.frame(table(df_100k$Region)) %>% arrange(desc(Freq)),
caption = "Frequency Region df_100k")
kable(as.data.frame(table(df_1k$Item.Type )) %>% arrange(desc(Freq)),
caption = "Frequency Item.Type df_1k")
kable(as.data.frame(table(df_100k$Item.Type )) %>% arrange(desc(Freq)),
caption = "Frequency Item Type 100k")
kable(as.data.frame(table(df_1k$Sales.Channel )) %>% arrange(desc(Freq)),
caption = "Frequency Sales Channel 1k")
kable(as.data.frame(table(df_100k$Sales.Channel )) %>% arrange(desc(Freq)),
caption = "Frequency Sales Channel 100k")
var_label(df_1k)
var_label(df_100k)
# Dimensions
dim_1k_tmp<-dim(df_1k)
dim_100k_tmp<-dim(df_100k)
# Class
class_1k_tmp<-sapply(df_1k,class)
class_100k_tmp<-sapply(df_100k,class)
column_name_1k_tmp <- "Order.ID"
# Count the number of duplicates in the specified column
num_duplicates_1k_tmp <- sum(duplicated(df_1k[[column_name_1k_tmp]]) |
duplicated(df_1k[[column_name_1k_tmp]],
fromLast = TRUE))
column_name_100k_tmp <- "Order.ID"
# Count the number of duplicates in the specified column
num_duplicates_100k_tmp <- sum(duplicated(df_100k[[column_name_100k_tmp]]) |
duplicated(df_100k[[column_name_100k_tmp]],
fromLast = TRUE))
na_null_cnt_tmp<-(sum(colSums(is.na(df_1k) | is.null(df_1k)))+
sum(colSums(is.na(df_100k) | is.null(df_100k))))
region_tmp<-unique(df_1k$Region)
country_len_tmp<-length(unique(df_1k$Country))
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
url_grocery<-"https://raw.githubusercontent.com/GitableGabe/Data624_Data/main/"
df_grocery<-read.csv(paste0(url_grocery, "GroceryDataSet.csv"))
View(df_grocery)
setwd("C:/Users/xusef/Documents/GitableGabe/Data624_Collab")
library(caret)
library(corrplot)
library(Cubist)
library(dplyr)
library(earth)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(readxl)
library(RANN)
library(rpart)
library(rpart.plot)
library(tidyr)
StudentData_df <- readxl::read_xlsx('Data/StudentData.xlsx')
StudentEval_df <- readxl::read_xlsx('Data/StudentEvaluation.xlsx')
View(StudentData_df)
glimpse(train_df)
library(Amelia)
glimpse(train_df)
library(Amelia)
library(Amelia)
train_df <- readxl::read_xlsx('Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('Data/StudentEvaluation.xlsx')
glimpse(train_df)
glimpse(test_df)
str(train_df)
str(test_df)
summary(train_df)
summary(test_df)
View(train_df)
View(train_df)
View(train_df)
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
VIM::aggr(train, numbers=T, sortVars=T, bars = FALSE, border= 'white',
cex.axis = .6,
ylab=c("Proportion of NAs", "Combinations"))
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE, border= 'white',
cex.axis = .6,
ylab=c("Proportion of NAs", "Combinations"))
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE, border= 'lightgreen',
cex.axis = .6,
ylab=c("NA Proportion", "Combinations"))
VIM::aggr(train_df, numbers=T, sortVars=T, bars = FALSE, border= 'lightblue',
cex.axis = .6,
ylab=c("NA Proportion", "Combinations"))
missing_data <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_data, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
labs(y = "NA Proportion", x = "Variables") +
coord_flip()  # Flipping coordinates for horizontal bars
missing_data <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_data, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
theme(
axis.text.x = element_text(size = 12, margin = margin(t = 5, b = 5)),  # Adjust margins around text
axis.text.y = element_text(size = 12, margin = margin(t = 5, b = 5))
)+
labs(y = "NA Proportion", x = "Variables") +
coord_flip()
missing_data <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_data, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
labs(y = "NA Proportion", x = "Variables") +
coord_flip()
dfSummary(train_df)
ctable(train_df)
view(dfSummary(train_df))
# Setting options for summarytools
st_options(
plain.ascii = FALSE,  # Use this for better rendering in RStudio Viewer or Jupyter Notebooks
style = "grid",       # Enhances the layout for graphical viewing
dfSummary.graph.magnif = 0.75,  # Adjust the size of graphs
dfSummary.max.tbl.width = 110,  # Adjust maximum table width
dfSummary.valid.col = FALSE,    # Hide 'Valid' column if preferred
dfSummary.na.col = TRUE         # Show a column with NA counts
)
st_options(
plain.ascii = FALSE,    # Enable HTML output for better rendering in HTML environments
style = "grid",         # Grid style for tables
dfSummary.graph.magnif = 0.75,  # Magnify graphs in the output
dfSummary.valid.col = FALSE,    # Toggle to hide/show 'Valid' column as needed
dfSummary.na.col = TRUE         # Toggle to show/hide NA counts column
)
# Generate the summary
df_summary <- dfSummary(train_df)
# Printing in RStudio's Viewer for a better visualization
print(df_summary, method = "viewer")
View(df_summary)
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = FALSE)
# Setting options for summarytools
st_options(
plain.ascii = FALSE,  # Use this for better rendering in RStudio Viewer or Jupyter Notebooks
style = "grid",       # Enhances the layout for graphical viewing
dfSummary.graph.magnif = 0.75,  # Adjust the size of graphs
dfSummary.max.tbl.width = 110,  # Adjust maximum table width
dfSummary.valid.col = FALSE,    # Hide 'Valid' column if preferred
dfSummary.na.col = TRUE         # Show a column with NA counts
)
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = FALSE)
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = TRUE)
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = TRUE)
print(df_summary, method = "render")
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
train_df <- readxl::read_xlsx('Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('Data/StudentEvaluation.xlsx')
glimpse(train_df)
str(train_df)
summary(train_df)
glimpse(test_df)
str(test_df)
summary(test_df)
missing_data <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_data, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
labs(y = "NA Proportion", x = "Variables") +
coord_flip()
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = TRUE)
df_summary <- dfSummary(train_df)
print(df_summary, method = "render")
DataExplorer::plot_histogram(train, nrow = 3L, ncol = 4L)
DataExplorer::plot_histogram(train_df, nrow = 3L, ncol = 4L)
# Convert data to long format
train_df_long <- train_df %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
library(tidyverse)
# Convert all columns to character before pivoting
train_df_long <- train_df %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
# Then plot histograms (although not typical for character data)
p <- ggplot(train_df_long, aes(x = value)) +
geom_histogram(stat = "count", fill = "blue", color = "black") +
facet_wrap(~variable, scales = "free", nrow = 3, ncol = 4) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
# Filter out only numeric columns
numeric_df <- train_df %>% select(where(is.numeric))
# Filter out only numeric columns
numeric_df <- train_df %>% select(where(is.numeric))
library(Amelia)
library(car)
library(caret)
library(corrplot)
library(Cubist)
library(DataExplorer)
library(dplyr)
library(e1071)
library(earth)
library(forcats)
library(forecast)
library(fpp3)
library(gbm)
library(ggplot2)
library(kableExtra)
library(MASS)
library(mice)
library(mlbench)
library(party)
library(randomForest)
library(RANN)
library(RColorBrewer)
library(readxl)
library(rpart)
library(rpart.plot)
library(summarytools)
library(tidyr)
library(VIM)
train_df <- readxl::read_xlsx('Data/StudentData.xlsx')
test_df <- readxl::read_xlsx('Data/StudentEvaluation.xlsx')
glimpse(train_df)
str(train_df)
summary(train_df)
glimpse(test_df)
str(test_df)
summary(test_df)
missing_data <- train_df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "na_proportion")
# Create a bar plot using ggplot2
ggplot(missing_data, aes(x = variable, y = na_proportion)) +
geom_bar(stat = "identity", fill = "skyblue", color = "lightblue") +
theme_minimal() +
labs(y = "NA Proportion", x = "Variables") +
coord_flip()
st_options(
plain.ascii = FALSE,
style = "grid",
dfSummary.graph.magnif = 0.75,
dfSummary.valid.col = FALSE,
dfSummary.na.col = TRUE,
footnote = NA  # Remove default footnotes
)
options(summarytools.print.css = TRUE, summarytools.use.viewer = TRUE)
df_summary <- dfSummary(train_df)
print(df_summary, method = "render")
# Filter out only numeric columns
numeric_df <- train_df %>% select(where(is.numeric))
# Filter out only numeric columns
numeric_df <- train_df %>% dplyr::select(where(is.numeric))
# Convert the numeric dataframe to long format
numeric_df_long <- numeric_df %>%
pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
# Calculate the number of numeric variables
num_vars <- ncol(numeric_df)
# Decide on a grid size
nrows <- ceiling(sqrt(num_vars))  # Number of rows
ncols <- ceiling(num_vars / nrows)  # Number of columns
# Create histograms
p <- ggplot(numeric_df_long, aes(x = value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~variable, scales = "free", nrow = nrows, ncol = ncols) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
DataExplorer::plot_histogram(train, nrow = 4L, ncol = 4L)
DataExplorer::plot_histogram(train, nrow = 3L, ncol = 4L)
DataExplorer::plot_histogram(train_df, nrow = 3L, ncol = 4L)
